{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delineate cities using A-DBSCAN\n",
    "\n",
    "This notebook contains the code used to create the city delineations. Because the procedure is computationally intensive, these steps were run in a series of hardware and in separate steps. Taken together, they implement the A-DBSCAN algorithm. The code presented here is thus published as an illustration of the steps followed. For a more flexible implementation of A-DBSCAN, please check the one published in PySAL on the [`esda`](https://github.com/pysal/esda) package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies & input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools, time, os, sys, traceback, sqlite3\n",
    "from tools import logger\n",
    "from time import gmtime, strftime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from tools import ADBSCAN\n",
    "\n",
    "# Path to sqlite created in the `extract_merge_buildings` notebook\n",
    "db_path = '/home/jovyan/work/cadastro.db'\n",
    "engine = create_engine('sqlite:////'+db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read relevant columns for all building footprints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varlist=['X', 'Y', 'geometry', 'localId', 'numberOfBuildingUnits']\n",
    "%time db = pd.read_sql((\"SELECT X, Y, localId, numberOfBuildingUnits \"\\\n",
    "                        \"FROM cadastro\"), engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up parameters, the logging function and check if we've done already any run, so we do not repeat it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epss = [2000]\n",
    "min_ptss = [2000]\n",
    "pct = 0.1\n",
    "reps = 1000\n",
    "\n",
    "out_dir = './revision/'\n",
    "\n",
    "def logger(txt, f='log_revision.txt', mode='a'):\n",
    "    fo = open(f, 'a')\n",
    "    fo.write(txt)\n",
    "    fo.close()\n",
    "    return txt\n",
    "\n",
    "done_fmp = [f.strip('bcn_').strip('sp_').strip('.feather').split('_') \\\n",
    "        for f in os.listdir(out_dir) if ('sp_' in f) and ('.feather' in f)]\n",
    "done_fmp = [(int(i[0].strip('mp')), int(i[1].strip('eps'))) for i in done_fmp]\n",
    "\n",
    "print(\"Completed solutions:\")\n",
    "[i for i in done_fmp if i[0]==2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of DBSCAN draws\n",
    "\n",
    "In the published version, city delineations are based on an ensemble of 1,000 draws, each of which computes DBSCAN on a sample and extends it to the rest of the dataset through a nearest-neighbor algorithm.\n",
    "\n",
    "Given our hardware, we could not hold in RAM 1,000 candidate solutions _and_ perform the subsequent steps required in the A-DBSCAN algorithm. For that reason, we broke the original algorithm into steps and performed each of them separate, writing to disk intermediate results.\n",
    "\n",
    "The following code computes A-DBSCAN 1,000, computing DBSCAN for 10% of the sample and extending it to the rest of the dataset through a nearest-neighbor regression. The result of each draw is written into a SQLite database (`results.db`) and further indexed on the observation and replication ID, as well as on its parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "errors = {}\n",
    "\n",
    "! rm log_revision.txt\n",
    "! mv results.db results_bu.db\n",
    "resDB = '/home/jovyan/work/results.db'\n",
    "results = create_engine('sqlite:////' + resDB)\n",
    "\n",
    "logger('', mode='w')\n",
    "\n",
    "for eps in epss:\n",
    "    for min_pts in min_ptss:\n",
    "        if (min_pts, eps) not in done_fmp:\n",
    "            # Random blocks\n",
    "            for rep_id in range(reps):\n",
    "                now = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "                print(logger('[eps=%i, min_pts=%i] %s\\n'%(eps, min_pts, now)))\n",
    "                try:\n",
    "                    # Computation\n",
    "                    t0 = time.time()\n",
    "                    np.random.seed(1234 + rep_id)\n",
    "                    solu = ADBSCAN(eps=eps, min_samples=min_pts, algorithm='ball_tree',\n",
    "                                   pct_exact=pct, reps=1, n_jobs=-1, keep_solus=True)\\\n",
    "                           .fit(db[['X', 'Y']])\n",
    "                    t1 = time.time()\n",
    "                    txt = '\\tComputation completed in %.2f sec.\\n'%(t1-t0)\n",
    "                    print(logger(txt))\n",
    "                    # Write out to results DB\n",
    "                    out = pd.DataFrame({'id': solu.solus.index,\n",
    "                                        'lbls': solu.solus['rep-0'].values,\n",
    "                                        'rep': rep_id,\n",
    "                                        'min_pts': min_pts,\n",
    "                                        'eps': eps})\n",
    "                    out.to_sql('results', \n",
    "                               con=results, \n",
    "                               if_exists='append',\n",
    "                               index=False)\n",
    "                    txt = '\\tSaved to disk in %.2f sec.\\n'%(time.time()-t1)\n",
    "                    print(logger(txt))\n",
    "                except:\n",
    "                    errors[(eps, min_pts)] = traceback.format_exc()\n",
    "                    print(logger(str(traceback.format_exc())))\n",
    "\n",
    "t2 = time.time()\n",
    "conn = sqlite3.connect(resDB)\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute(\"CREATE INDEX id ON results (id);\")\n",
    "c.execute(\"CREATE INDEX rep ON results (rep);\")\n",
    "c.execute(\"CREATE INDEX min_pts ON results (min_pts);\")\n",
    "c.execute(\"CREATE INDEX eps ON results (eps);\")\n",
    "txt = '\\tIndices created in %.2f sec.\\n'%(time.time()-t2)\n",
    "print(logger(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export SQLite file to plain csv\n",
    "\n",
    "The output turned out to be relatively large in size (+200GB) and thus not efficient to work with in SQLite. After the computations above, we decided to switch and work with [`dask`](https://dask.org/), which does not play well with SQLite. Below the output database is converted into a `results.csv` file.\n",
    "\n",
    "Set up the operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from time import gmtime, strftime\n",
    "\n",
    "cadastro = '/Users/dani/Dropbox/Cadastre/01 Catastro maps/sqlite_db/cadastro.db'\n",
    "con_cat = create_engine('sqlite:////'+cadastro)\n",
    "\n",
    "resDB = '/Users/dani/Desktop/results.db'\n",
    "results = create_engine('sqlite:////' + resDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "read = 0\n",
    "fo = open('results.csv', 'w')\n",
    "fo.write('id,lbls,rep\\n')\n",
    "fo.close()\n",
    "def logger(txt, f='/Users/dani/Dropbox/Cadastre/02_area_delineation/log_tocsv_hut8.txt', mode='a'):\n",
    "    fo = open(f, 'a')\n",
    "    fo.write(txt)\n",
    "    fo.close()\n",
    "    return txt\n",
    "logger('', mode='w')\n",
    "errors = {}\n",
    "\n",
    "reader = pd.read_sql(\"SELECT * FROM results;\", results, chunksize=12069635)\n",
    "for chunk in reader:\n",
    "    try:\n",
    "        now = strftime('%Y-%m-%d %H:%M:%S', gmtime())\n",
    "        print(logger(f\"{now} | Currently {read} read\\n\"))\n",
    "        if (chunk.loc[0, 'min_pts']==2000) and (chunk.loc[0, 'eps']==2000) and (chunk['rep'].unique().shape[0] == 1):\n",
    "            chunk = chunk.loc[:, ['id', 'rep', 'lbls']]\n",
    "            chunk.to_csv('results.csv', mode='a',\n",
    "                         header=False, index=False)\n",
    "            read+=chunk.shape[0]\n",
    "        else:\n",
    "            print(logger(\"min_pts or eps are not 2,000 so exiting...\"))\n",
    "            break\n",
    "    except:\n",
    "        errors[(eps, min_pts)] = traceback.format_exc()\n",
    "        print(logger(str(traceback.format_exc())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-labelling of solutions\n",
    "\n",
    "With independent candidate solutions from each draw written on a `.csv` file, the next step involved re-labelling them so they are comparable across solutions. This remapping uses the same logic as the one embedded in the A-DBSCAN implementation in `pysal/esda`, but it is performed in a modular way, separate from the previous and subsequent steps.\n",
    "\n",
    "The final output of this process is a folder (`remapped_lbls/`) with a separate `.parquet` file for each solution and using a standardised labelling across files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tools\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from sqlalchemy import create_engine\n",
    "from scipy.spatial import cKDTree\n",
    "from importlib import reload\n",
    "from tools import logger\n",
    "from time import gmtime, strftime\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'results.csv'\n",
    "db = dd.read_csv(url).rename(columns={'lbls': 'rep',\n",
    "                                      'rep': 'lbls'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick solution with most labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # read\n",
    "    ref_soluIDO = pd.read_csv('results_most_labels.csv', index_col='rep')\n",
    "except:\n",
    "    ref_soluID = db.groupby(['rep', 'lbls'])\\\n",
    "                   .size()\\\n",
    "                   .reset_index()\\\n",
    "                   .drop(0, axis=1)\\\n",
    "                   .groupby('rep')\\\n",
    "                   .size()\\\n",
    "                   .nlargest(1)\n",
    "\n",
    "    ! rm log_dask.txt\n",
    "    print(logger(f\"Executing pick of solutions with most labels | \"\\\n",
    "                 f\"{strftime('%Y-%m-%d %H:%M:%S', gmtime())}\\n\", 'log_dask.txt'))\n",
    "    with ProgressBar():\n",
    "        ref_soluIDO = ref_soluID.compute()\n",
    "    print(logger(f\"Computed pick of solutions with most labels | \"\\\n",
    "                 f\"{strftime('%Y-%m-%d %H:%M:%S', gmtime())}\\n\", 'log_dask.txt'))\n",
    "\n",
    "    ref_soluIDO.to_csv(url.replace('.csv', '_most_labels.csv'),\n",
    "                       header=['Count'])\n",
    "    print(logger(f\"Written pick of solutions with most labels | \"\\\n",
    "                 f\"{strftime('%Y-%m-%d %H:%M:%S', gmtime())}\\n\", 'log_dask.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remap labels to standardise across solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load reference solution and XY coordinates (from `parquet` file, which was extracted from `cadastro.db`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time xys = pd.read_parquet('xys.parquet.gzip')\n",
    "\n",
    "try:\n",
    "    ref_soluO = pd.read_parquet('ref_soluO.parquet.gzip')\\\n",
    "                  .set_index('id')\\\n",
    "                  ['lbls']\n",
    "except:\n",
    "    print(\"Extracting reference solution...\")\n",
    "    ref_solu = db.loc[db['rep']==ref_soluIDO.index[0], ['id', 'lbls']]\n",
    "    with ProgressBar():\n",
    "        ref_soluO = ref_solu.compute()\n",
    "    ref_soluO = ref_soluO.set_index('id')['lbls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute centroids from reference solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ref_centroids = xys.groupby(ref_soluO)\\\n",
    "                   .apply(lambda xys: xys.mean())\\\n",
    "                   .drop(-1, errors='ignore')\n",
    "ref_kdt = cKDTree(ref_centroids)\n",
    "pars = (ref_centroids, ref_kdt, xys, ['X', 'Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remap labels across all solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tools)\n",
    "def align_and_remap(new_lbls, pars, write=False):\n",
    "    ref_centroids, ref_kdt, xys, xy_name = pars\n",
    "    topass = new_lbls.join(xys, on='id')\n",
    "    remapped_ids = tools.remap_lbls_single(topass['lbls'], \n",
    "                                           (ref_centroids, ref_kdt, \n",
    "                                            topass[xy_name], xy_name))\n",
    "    remapped_lbls = new_lbls['lbls'].map(remapped_ids)\\\n",
    "                                    .fillna(-1)\\\n",
    "                                    .astype(int)\n",
    "    rep_id = new_lbls['rep'].iloc[0]\n",
    "    outF = f\"remapped_lbls/rep_{rep_id}.parquet\"\n",
    "    remapped_lbls = remapped_lbls.reset_index()\\\n",
    "                                 .assign(rep=rep_id)\\\n",
    "                                 .rename(columns={'index': 'id'})\n",
    "    if write:\n",
    "        remapped_lbls.to_parquet(outF)\n",
    "    return remapped_lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chunks = 5\n",
    "n = ref_soluO.shape[0]\n",
    "reps = 1000\n",
    "rows_by_chunk = n * reps / n_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open('log_dask_remapping.txt', 'w')\n",
    "fo.close()\n",
    "! rm -r remapped_lbls\n",
    "! mkdir remapped_lbls\n",
    "\n",
    "print(logger(f\"Starting sequential remapping of labels | \"\\\n",
    "             f\"{strftime('%Y-%m-%d %H:%M:%S', gmtime())}\\n\", 'log_dask_remapping.txt'))\n",
    "reader = pd.read_csv('results.csv', chunksize=n)\n",
    "for i, solu in enumerate(reader):\n",
    "    solu = solu.rename(columns={'lbls': 'rep',\n",
    "                                'rep': 'lbls'})\n",
    "    outF = align_and_remap(solu, pars, write=True)\n",
    "    logger(f\"Solution {i+1}/1000 remapped | \"\\\n",
    "           f\"{strftime('%Y-%m-%d %H:%M:%S', gmtime())}\\n\", 'log_dask_remapping.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect winner solution and votes\n",
    "\n",
    "In this step, each re-labelled solution is used to count how often each label is attributed to each observation. This is used later to determine whether a building is part of a city in a robust manner or not (if not, they are not assigned into any city). The input is the folder of relabelled `.parquet` files; the output is a single file (`solution_rep1000_eps2000_mp2000_thr90.parquet`) containing a table with a row for each building and two columns, ones for the winning label, and another for its frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_store(store, lbls):\n",
    "    def _update_record(entry_lbl):\n",
    "        entry, lbl = entry_lbl\n",
    "        if lbl in entry:\n",
    "            entry[lbl] += 1\n",
    "        else:\n",
    "            entry[lbl] = 1\n",
    "    _ = list(map(_update_record, zip(store, lbls)))\n",
    "    return store\n",
    "\n",
    "def pick_winner_vote(store_entry):\n",
    "    lbl_count = pd.Series(store_entry)\n",
    "    return lbl_count.nlargest(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open('log_dask_win_vote.txt', 'w')\n",
    "fo.close()\n",
    "\n",
    "print(logger(f\"Starting to count votes | \"\\\n",
    "             f\"{strftime('%Y-%m-%d %H:%M:%S', gmtime())}\\n\", 'log_dask_win_vote.txt'))\n",
    "# Set up a `store`\n",
    "store = pd.read_parquet('remapped_lbls/rep_0.parquet')\n",
    "store = [{} for _ in range(store.shape[0])]\n",
    "# Loop over each remapped solution\n",
    "for solu in os.listdir('remapped_lbls/'):\n",
    "    print(logger(f\"Processing {solu} | \"\\\n",
    "                 f\"{strftime('%Y-%m-%d %H:%M:%S', gmtime())}\\n\", 'log_dask_win_vote.txt'))\n",
    "    ## Load file\n",
    "    tmp = pd.read_parquet(f\"remapped_lbls/{solu}\")\n",
    "    ## Update `store` by checking if lbl in store[id]\n",
    "    ##and creating it otherwise\n",
    "    store = update_store(store, \n",
    "                         tmp['lbls'].values)\n",
    "print(logger(f\"Done updating votes | \"\\\n",
    "             f\"{strftime('%Y-%m-%d %H:%M:%S', gmtime())}\\n\", 'log_dask_win_vote.txt'))\n",
    "# Pick winner and vote from `store`\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "win_vote = pool.map(pick_winner_vote, store)\n",
    "pool.close()\n",
    "print(logger(f\"Done counting votes in parallel | \"\\\n",
    "             f\"{strftime('%Y-%m-%d %H:%M:%S', gmtime())}\\n\", 'log_dask_win_vote.txt'))\n",
    "# Write winner and vote to disk\n",
    "win_vote = pd.concat(win_vote).reset_index()\\\n",
    "                              .rename(columns={'index':'lbls',\n",
    "                                               0: 'pct'})\\\n",
    "                              .reset_index()\\\n",
    "                              .rename(columns={'index': 'id'})\n",
    "win_vote['pct'] = win_vote['pct'] * 100 / 1000\n",
    "win_vote.to_parquet('win_vote.parquet')\n",
    "print(logger(f\"Done with the process | \"\\\n",
    "             f\"{strftime('%Y-%m-%d %H:%M:%S', gmtime())}\\n\", 'log_dask_win_vote.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filter extra-noise (<90% = `-1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _ = win_vote.head()\n",
    "except:\n",
    "    win_vote = pd.read_parquet('../output/revision/win_vote.parquet')\n",
    "\n",
    "lbl_type = type(win_vote.loc[0, 'lbls'])\n",
    "win_vote.loc[win_vote['pct'] < 90, 'lbls'] = lbl_type(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_vote.to_parquet('../output/revision/solution_rep1000_eps2000_mp2000_thr90.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn labels into polygons\n",
    "\n",
    "At this point, we know in which city each building is, and we are ready to create the delineation of city boundaries. The intput of this step is the `solution_rep1000_eps2000_mp2000_thr90.parquet` table, and the output is a GeoPackage (`solution_rep1000_eps2000_mp2000_thr90.gpkg`) with the polygons of all identified cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import tools\n",
    "\n",
    "win_vote = pandas.read_parquet('solution_rep1000_eps2000_mp2000_thr90.parquet')\n",
    "lbl_type = type(win_vote.loc[0, 'lbls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace `outF` with final set of labels\n",
    "xys = pd.read_parquet('xys.parquet.gzip')\n",
    "%time polys = tools.lbls2polys_parallel(win_vote['lbls'], xys, \\\n",
    "                               noise=lbl_type(-1), gdf=True)\n",
    "polys.to_file('solution_rep1000_eps2000_mp2000_thr90.gpkg', driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
